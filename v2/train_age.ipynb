{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/michaelzeng/.local/lib/python3.6/site-packages (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataclasses'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1f42b90e9214>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# !pip install matplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# import numpy as np\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;31m# needs to be after the above ATen bindings so we can overwrite from Python side\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_lowrank\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvd_lowrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca_lowrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m from .overrides import (\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUninitializedParameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUninitializedBuffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataParallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIdentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBilinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyLinear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mConvTranspose1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConvTranspose2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConvTranspose3d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mLazyConv1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyConv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyConv3d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyConvTranspose1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyConvTranspose2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyConvTranspose3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUninitializedParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_docs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreproducibility_notes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf32_notes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mboolean_dispatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_overload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBroadcastingList1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBroadcastingList2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBroadcastingList3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m from ..overrides import (\n\u001b[1;32m     13\u001b[0m     \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sources\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_source_lines_and_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mangling\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpackage_mangling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/package/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msys_importer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpackage_exporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEmptyMatchError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPackageExporter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPackagingError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpackage_importer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPackageImporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/package/package_exporter.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataclasses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0menum\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataclasses'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "# !pip install numpy\n",
    "# !pip install torch\n",
    "# !pip install torchvision\n",
    "# !pip install pandas\n",
    "# !pip install opencv-python\n",
    "# !pip install matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import csv\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset_age import FacesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creating the Neural Network Class\"\"\"\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Input: 48 x 48 x 1 = 2304\n",
    "        ### Inputs to Conv2d: Incoming layers, outgoing layers, Frame size\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 2, 3)  #48 --> 46\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  #46 --> 23\n",
    "        self.conv2 = nn.Conv2d(2, 4, 3, stride=2)  #23 --> 11\n",
    "        self.conv3 = nn.Conv2d(4, 8, 3, stride=2) #11 --> 5\n",
    "\n",
    "        # Activation function to use\n",
    "        self.activation = F.relu\n",
    "\n",
    "        self.fc1 = nn.Linear(200, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.activation(self.conv2(x))\n",
    "        x = self.activation(self.conv3(x))\n",
    "        x = x.view(-1, 200)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Setting up neural network parameters, defining accuracy function\"\"\"\n",
    "batch_size = 32\n",
    "# learning_rate = 0.000000001  #11/12 2:07 PM (works, small range of 14-31)\n",
    "# learning_rate = 0.0000000005   #11/12 2:15 PM (works, range of -7 to 50. seems to be making real (but inaccurate predictions))\n",
    "# learning_rate = 0.00000000025\n",
    "learning_rate = 0.001\n",
    "num_epochs = 35\n",
    "\n",
    "data_path = \"../age_gender.csv\"\n",
    "\n",
    "dataset = FacesDataset(csv_file=data_path)\n",
    "num_data_items = dataset.__len__()\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [int(round(num_data_items*0.51)), int(round(num_data_items*0.49))])\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net()\n",
    "# model.to(device)\n",
    "\n",
    "# criterion = nn.L1Loss()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    \"\"\"\n",
    "    Checks accuracy of the model by running it on the data in the dataloader passed as a parameter\n",
    "    \n",
    "    The closer the returned score is to 0, the better\n",
    "    \"\"\"\n",
    "    num_correct_age = 0\n",
    "    num_samples = loader.__len__()\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():  #speeds up process\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)   #shape: (batch size, 48, 48)\n",
    "            y = y.to(device=device)   #shape: (batch size, 3)\n",
    "            \n",
    "            #GETTING AND FORMATTING MODEL PREDICTIONS\n",
    "            x = x.unsqueeze(1)   #Add a dimension to the tensor for number of channels (which is 1)\n",
    "            scores = model(x.float())   #Shape: (batch size, 3)\n",
    "#             print(\"scores: \" + str(scores))\n",
    "            \n",
    "            #GETTING NUM CORRECT\n",
    "#             race = torch.round(scores[:,1].clone())    #Getting integer-rounded copy of races\n",
    "#             gender = torch.round(scores[:,2].clone())  #Getting integer-rounded copy of gender\n",
    "#             scores = torch.column_stack((torch.round(scores[:,0]), race))  #recreating batch sizex3 tensor with integer rounded age, race, and gender\n",
    "#             scores = torch.column_stack((scores, gender))\n",
    "#             print(\"scores: \" + str(scores))\n",
    "#             print(\"y: \" + str(y))\n",
    "            \n",
    "            #CALCULATING ACCURACY SCORE\n",
    "            age_diffs = torch.abs(scores - y)\n",
    "            age_diff_avg = torch.mean(age_diffs)\n",
    "            \n",
    "#             age_std = torch.std(age_diffs)\n",
    "            \n",
    "#             age_accuracy = age_diff_avg/age_std\n",
    "#             total_accuracy = (age_accuracy + race_accuracy + gender_accuracy) / 3\n",
    "\n",
    "#             print(\"------------------------\")\n",
    "#             print(\"age_accuracy: \" + str(age_accuracy))\n",
    "#             print(\"total_accuracy: \" + str(total_accuracy))\n",
    "#             print(\"------------------------\")\n",
    "        \n",
    "#         print(f'accuracy score (the closer to zero, the better): {total_accuracy}')\n",
    "    return age_diff_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Training\"\"\"\n",
    "\n",
    "all_losses = []\n",
    "all_train_acc = []\n",
    "all_test_acc = []\n",
    "for epoch in range(num_epochs):  #Looping through epochs\n",
    "    losses = []\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):   #Looping through batches\n",
    "        #Get data to cuda if possible\n",
    "        data = data.to(device=device)             #data is a torch tensor of [batch size] 48x48 images (shape=[batch size,48,48])\n",
    "        data = data.unsqueeze(1)                  #Add a dimension to the tensor for number of channels (which is 1)\n",
    "#         print(\"data.shape: \" + str(data.shape))\n",
    "        targets = targets.to(device=device)       #data is a torch tensor of (shape=[batch size,1])\n",
    "#         print(\"targets.shape: \" + str(targets.shape))\n",
    "#         print(\"data[0,:,:].shape: \" + str(np.array(data[0,:,:].shape)))\n",
    "#         cv2.imwrite(\"test.png\", np.array(data[0,:,:]))\n",
    "        \n",
    "        #Forward prop\n",
    "        scores = model(data.float()).reshape(-1)\n",
    "        \n",
    "        #Calculating Accuracy Score\n",
    "        age_diffs = torch.abs(scores - targets)\n",
    "        train_acc = torch.mean(age_diffs).item() * 100\n",
    "        \n",
    "\n",
    "        loss = criterion(scores, targets)\n",
    "#         print(loss)\n",
    "        \n",
    "        #Backward prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()  #gradient descent\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    l = sum(losses)/len(losses)\n",
    "    all_losses.append(l)\n",
    "    \n",
    "    all_train_acc.append(train_acc)\n",
    "    test_acc = check_accuracy(test_loader, model)*100\n",
    "    all_test_acc.append(test_acc)\n",
    "    \n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {l}, Train Acc: {train_acc}, Test Acc: {test_acc}\")\n",
    "#     print(f\"Epoch: {epoch + 1}, Loss: {l}, Test Acc: {test_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plotting Results\"\"\"\n",
    "\n",
    "# print(\"Checking final accuracy on training data.\")\n",
    "# check_accuracy(train_loader, model)\n",
    "\n",
    "# print(\"Checking final accuracy on testing data.\")\n",
    "# check_accuracy(test_loader, model)\n",
    "\n",
    "\n",
    "\n",
    "def plot(loss, train_acc, test_acc):\n",
    "    plt.figure()\n",
    "    plt.scatter(range(0, len(all_losses)), loss)\n",
    "    plt.plot(range(0, len(all_losses)), loss)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(range(0, len(train_acc)), train_acc)\n",
    "    plt.scatter(range(0, len(test_acc)), test_acc)\n",
    "    plt.plot(range(0, len(train_acc)), train_acc)\n",
    "    plt.plot(range(0, len(test_acc)), test_acc)\n",
    "    \n",
    "    now = datetime.now()\n",
    "    # dd/mm/YY H:M:S\n",
    "    dt_string = now.strftime(\"%d,%m,%Y_%H,%M,%S\")\n",
    "#     plt.savefig('../plots/loss_accuracy_' + dt_string + '.png')\n",
    "\n",
    "print(all_losses)\n",
    "plot(all_losses, all_train_acc, all_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Getting prediction on single custom image\"\"\"\n",
    "IMG_FILE = \"../test_face2.jpg\"\n",
    "\n",
    "test_img = torch.Tensor(cv2.cvtColor(cv2.imread(IMG_FILE), cv2.COLOR_BGR2GRAY))   #getting image with shape (48, 48)\n",
    "test_img = test_img.unsqueeze(0).unsqueeze(0)  #adding 2 dimensions to the image to get it to shape (1, 1, 48, 48). The 1st dimension represents batch of 1, the second represents color channels (I think)\n",
    "outputs = model(test_img)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Getting prediction on a random image from the dataset (and retreiving label)\"\"\"\n",
    "import random\n",
    "item_tuple = dataset.__getitem__(random.randint(0, dataset.__len__()-1))\n",
    "image = item_tuple[0]\n",
    "label = item_tuple[1]*100\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "image = torch.Tensor(image)\n",
    "image = image.unsqueeze(0).unsqueeze(0)  #adding 2 dimensions to the image to get it to shape (1, 1, 48, 48). The 1st dimension represents batch of 1, the second represents color channels (I think)\n",
    "outputs = model(image) * 100\n",
    "print(\"prediction: %f.      Label: %f\" % (outputs, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Getting prediction on a random image from the dataset (and retreiving label)\"\"\"\n",
    "# import random\n",
    "# item_tuple = dataset.__getitem__(random.randint(0, dataset.__len__()-1))\n",
    "# image = item_tuple[0]\n",
    "# label = item_tuple[1]\n",
    "\n",
    "# %matplotlib inline\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.imshow(image)\n",
    "# plt.show()\n",
    "\n",
    "# __, img = torch.utils.data.random_split(dataset, [num_data_items-1, 1])\n",
    "# loader = DataLoader(dataset=img, batch_size=1, shuffle=True)\n",
    "# for batch_idx, (data, targets) in enumerate(loader):   #Looping through batches\n",
    "#     #Get data to cuda if possible\n",
    "#     data = data.to(device=device)             #data is a torch tensor of [batch size] 48x48 images (shape=[batch size,48,48])\n",
    "#     data = data.unsqueeze(1)                  #Add a dimension to the tensor for number of channels (which is 1)\n",
    "\n",
    "#     #Forward prop\n",
    "#     scores = model(data.float()).reshape(-1)\n",
    "\n",
    "#     print(\"prediction: %f.      Label: %d\" % (scores.item(), int(label.item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
