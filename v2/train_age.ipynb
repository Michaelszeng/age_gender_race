{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3a1825",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "# !pip install numpy\n",
    "# !pip install torch\n",
    "# !pip install torchvision\n",
    "# !pip install pandas\n",
    "# !pip install opencv-python\n",
    "# !pip install matplotlib\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import csv\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset_age import FacesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e46022d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creating the Neural Network Class\"\"\"\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Input: 48 x 48 x 1 = 2304\n",
    "        ### Inputs to Conv2d: Incoming layers, outgoing layers, Frame size\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 2, 3)  #48 --> 46\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  #46 --> 23\n",
    "        self.conv2 = nn.Conv2d(2, 4, 3, stride=2)  #23 --> 11\n",
    "        self.conv3 = nn.Conv2d(4, 8, 3, stride=2) #11 --> 5\n",
    "\n",
    "        # Activation function to use\n",
    "        self.activation = F.relu\n",
    "    \n",
    "        self.fc1 = nn.Linear(200, 50)\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.5)    #p = probability of a neuron being dropped\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        self.dropout2 = torch.nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.activation(self.conv2(x))\n",
    "        x = self.activation(self.conv3(x))\n",
    "        x = x.view(-1, 200)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ffbf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Setting up neural network parameters, defining accuracy function\"\"\"\n",
    "batch_size = 32\n",
    "# learning_rate = 0.000000001  #11/12 2:07 PM (works, small range of 14-31)\n",
    "# learning_rate = 0.0000000005   #11/12 2:15 PM (works, range of -7 to 50. seems to be making real (but inaccurate predictions))\n",
    "learning_rate = 0.001\n",
    "num_epochs = 35\n",
    "\n",
    "data_path = \"../age_gender.csv\"\n",
    "\n",
    "dataset = FacesDataset(csv_file=data_path)\n",
    "num_data_items = dataset.__len__()\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [int(round(num_data_items*0.51)), int(round(num_data_items*0.49))])\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "# model.to(device)\n",
    "\n",
    "# criterion = nn.L1Loss()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    \"\"\"\n",
    "    Checks accuracy of the model by running it on the data in the dataloader passed as a parameter\n",
    "    \n",
    "    The closer the returned score is to 0, the better\n",
    "    \"\"\"\n",
    "    num_correct_age = 0\n",
    "    num_samples = loader.__len__()\n",
    "    \n",
    "    model.eval()  #Setting to eval mode will cause the model to ignore the dropout layers\n",
    "    \n",
    "    with torch.no_grad():  #speeds up process\n",
    "        age_diffs_total = 0\n",
    "        num_batches = 0\n",
    "        for batch_idx, (x, y) in enumerate(loader):   #Looping through batches\n",
    "            x = x.to(device=device)   #shape: (batch size, 48, 48)\n",
    "            y = y.to(device=device)   #shape: (batch size, 3)\n",
    "            \n",
    "            #GETTING AND FORMATTING MODEL PREDICTIONS\n",
    "            x = x.unsqueeze(1)   #Add a dimension to the tensor for number of channels (which is 1)\n",
    "#             scores = model(x.float())   #Shape: (batch size, 3)\n",
    "            scores = model(x.float()).reshape(-1)   #Shape: (batch size, 3)\n",
    "#             print(\"scores: \" + str(scores))\n",
    "            \n",
    "            #CALCULATING ACCURACY SCORE\n",
    "            age_diffs = torch.abs(scores - y)\n",
    "            age_diff_avg = torch.mean(age_diffs)\n",
    "            \n",
    "            age_diffs_total += age_diff_avg\n",
    "            num_batches += 1\n",
    "        \n",
    "#         print(f'accuracy score (the closer to zero, the better): {total_accuracy}')\n",
    "    return age_diffs_total/num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba574bcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.09838522544436196, Train Acc: 16.248716354370117, Test Acc: 16.25584602355957\n",
      "Epoch: 2, Loss: 0.05576876205485807, Train Acc: 14.727733612060547, Test Acc: 14.715920448303223\n",
      "Epoch: 3, Loss: 0.04211352880620373, Train Acc: 14.020133018493652, Test Acc: 14.021296501159668\n",
      "Epoch: 4, Loss: 0.03476220937741418, Train Acc: 12.65244197845459, Test Acc: 12.75205135345459\n",
      "Epoch: 5, Loss: 0.03065042436448118, Train Acc: 12.61119556427002, Test Acc: 12.670896530151367\n",
      "Epoch: 6, Loss: 0.028105419917554452, Train Acc: 11.397470474243164, Test Acc: 11.512516975402832\n",
      "Epoch: 7, Loss: 0.027398750062775677, Train Acc: 11.001919746398926, Test Acc: 11.150081634521484\n",
      "Epoch: 8, Loss: 0.026040949880899417, Train Acc: 11.087725639343262, Test Acc: 11.249519348144531\n",
      "Epoch: 9, Loss: 0.025266979471164405, Train Acc: 10.585174560546875, Test Acc: 10.860873222351074\n",
      "Epoch: 10, Loss: 0.02464022756450706, Train Acc: 10.999524116516113, Test Acc: 11.183423042297363\n",
      "Epoch: 11, Loss: 0.023887716504750113, Train Acc: 10.440195083618164, Test Acc: 10.666597366333008\n",
      "Epoch: 12, Loss: 0.02335663342715374, Train Acc: 10.805424690246582, Test Acc: 11.110212326049805\n",
      "Epoch: 13, Loss: 0.02325103985066846, Train Acc: 10.267984390258789, Test Acc: 10.562799453735352\n",
      "Epoch: 14, Loss: 0.022738909622329096, Train Acc: 10.178644180297852, Test Acc: 10.476509094238281\n",
      "Epoch: 15, Loss: 0.022628191912734005, Train Acc: 10.087057113647461, Test Acc: 10.43816089630127\n",
      "Epoch: 16, Loss: 0.021967310399290115, Train Acc: 9.80562973022461, Test Acc: 10.227428436279297\n",
      "Epoch: 17, Loss: 0.022227773524170356, Train Acc: 9.864066123962402, Test Acc: 10.317901611328125\n",
      "Epoch: 18, Loss: 0.021748142626146397, Train Acc: 9.656965255737305, Test Acc: 10.11755657196045\n",
      "Epoch: 19, Loss: 0.022040907525156857, Train Acc: 9.769472122192383, Test Acc: 10.272638320922852\n",
      "Epoch: 20, Loss: 0.021443511923607536, Train Acc: 9.932073593139648, Test Acc: 10.440279006958008\n",
      "Epoch: 21, Loss: 0.021295018888339793, Train Acc: 9.638946533203125, Test Acc: 10.168330192565918\n",
      "Epoch: 22, Loss: 0.021021853217106097, Train Acc: 9.596288681030273, Test Acc: 10.18667221069336\n",
      "Epoch: 23, Loss: 0.020936885511098558, Train Acc: 9.587013244628906, Test Acc: 10.204073905944824\n",
      "Epoch: 24, Loss: 0.020597422916796945, Train Acc: 9.3373441696167, Test Acc: 9.958903312683105\n",
      "Epoch: 25, Loss: 0.020117984622687338, Train Acc: 9.709883689880371, Test Acc: 10.249895095825195\n",
      "Epoch: 26, Loss: 0.02054366191464757, Train Acc: 9.15324878692627, Test Acc: 9.882332801818848\n",
      "Epoch: 27, Loss: 0.020064284442308008, Train Acc: 9.189799308776855, Test Acc: 9.927985191345215\n",
      "Epoch: 28, Loss: 0.020152192262232936, Train Acc: 9.247339248657227, Test Acc: 9.999017715454102\n",
      "Epoch: 29, Loss: 0.02064020041913464, Train Acc: 9.187967300415039, Test Acc: 9.952959060668945\n",
      "Epoch: 30, Loss: 0.019762956840355717, Train Acc: 9.132308959960938, Test Acc: 9.886466026306152\n",
      "Epoch: 31, Loss: 0.019584186312313828, Train Acc: 9.040630340576172, Test Acc: 9.887493133544922\n",
      "Epoch: 32, Loss: 0.01968861109128705, Train Acc: 8.911778450012207, Test Acc: 9.772624015808105\n",
      "Epoch: 33, Loss: 0.019745787948113745, Train Acc: 9.42972183227539, Test Acc: 10.229528427124023\n",
      "Epoch: 34, Loss: 0.01937713875883707, Train Acc: 9.03530502319336, Test Acc: 9.841580390930176\n",
      "Epoch: 35, Loss: 0.019447458257514334, Train Acc: 8.992365837097168, Test Acc: 9.849143028259277\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Training\"\"\"\n",
    "\n",
    "all_losses = []\n",
    "all_train_acc = []\n",
    "all_test_acc = []\n",
    "for epoch in range(num_epochs):  #Looping through epochs\n",
    "    losses = []\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):   #Looping through batches\n",
    "        #Get data to cuda if possible\n",
    "        data = data.to(device=device)             #data is a torch tensor of [batch size] 48x48 images (shape=[batch size,48,48])\n",
    "        data = data.unsqueeze(1)                  #Add a dimension to the tensor for number of channels (which is 1)\n",
    "#         print(\"data.shape: \" + str(data.shape))\n",
    "        targets = targets.to(device=device)       #data is a torch tensor of (shape=[batch size,1])\n",
    "#         print(\"targets.shape: \" + str(targets.shape))\n",
    "#         print(\"data[0,:,:].shape: \" + str(np.array(data[0,:,:].shape)))\n",
    "#         cv2.imwrite(\"test.png\", np.array(data[0,:,:]))\n",
    "        \n",
    "        #Forward prop\n",
    "        scores = model(data.float()).reshape(-1)\n",
    "        \n",
    "        #Calculating Accuracy Score\n",
    "        #Old method (not using check_accuracy())\n",
    "#         age_diffs = torch.abs(scores - targets)\n",
    "#         train_acc = torch.mean(age_diffs).item() * 100        \n",
    "\n",
    "        loss = criterion(scores, targets)\n",
    "#         print(loss)\n",
    "        \n",
    "        #Backward prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()  #gradient descent\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    #Calculating Accuray Score using check_accuracy()\n",
    "    train_acc = check_accuracy(train_loader, model) * 100\n",
    "    all_train_acc.append(train_acc)\n",
    "    test_acc = check_accuracy(test_loader, model) * 100\n",
    "    all_test_acc.append(test_acc)\n",
    "    \n",
    "    #Calculating Loss\n",
    "    l = sum(losses)/len(losses)\n",
    "    all_losses.append(l)\n",
    "    \n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {l}, Train Acc: {train_acc}, Test Acc: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c60b360c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cdda5050d2f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m#     plt.savefig('../plots/loss_accuracy_' + dt_string + '.png')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_train_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_test_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-cdda5050d2f3>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(loss, train_acc, test_acc)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#Creating Scatter Plot for Accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m         \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2894\u001b[0m         \u001b[0mplotnonfinite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplotnonfinite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2896\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2897\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 **kwargs)\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4437\u001b[0m         \u001b[0;31m# unless its argument is a masked array.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4438\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4439\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4441\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, a, *args, **params)\u001b[0m\n\u001b[1;32m   6768\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6770\u001b[0;31m         \u001b[0mmarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6771\u001b[0m         \u001b[0mmethod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6772\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype)\u001b[0m\n\u001b[1;32m   7996\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7997\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7998\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmasked_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, mask, dtype, copy, subok, ndmin, fill_value, keep_mask, hard_mask, shrink, order, **options)\u001b[0m\n\u001b[1;32m   2867\u001b[0m                     \u001b[0;31m# If data is a sequence of masked array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2868\u001b[0m                     mask = np.array([getmaskarray(np.asanyarray(m, dtype=mdtype))\n\u001b[0;32m-> 2869\u001b[0;31m                                                     for m in data], dtype=mdtype)\n\u001b[0m\u001b[1;32m   2870\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m                     \u001b[0;31m# If data is nested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2867\u001b[0m                     \u001b[0;31m# If data is a sequence of masked array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2868\u001b[0m                     mask = np.array([getmaskarray(np.asanyarray(m, dtype=mdtype))\n\u001b[0;32m-> 2869\u001b[0;31m                                                     for m in data], dtype=mdtype)\n\u001b[0m\u001b[1;32m   2870\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2871\u001b[0m                     \u001b[0;31m# If data is nested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \"\"\"\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;31m# Wrap Numpy array again in a suitable tensor when done, to support e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANT0lEQVR4nO3cYYjkd33H8ffHO1NpjKb0VpC706T00njYQtIlTRFqirZc8uDugUXuIFgleGAbKVWEFEuU+MiGWhCu1ZOKVdAYfSALntwDjQTEC7chNXgXItvTeheFrDHNk6Ax7bcPZtKdrneZf3Zndy/7fb/gYP7/+e3Mlx97752d2ZlUFZKk7e8VWz2AJGlzGHxJasLgS1ITBl+SmjD4ktSEwZekJqYGP8lnkzyZ5PuXuD5JPplkKcmjSW6c/ZiSpPUa8gj/c8CBF7n+VmDf+N9R4F/WP5YkadamBr+qHgR+/iJLDgGfr5FTwNVJXj+rASVJs7FzBrexGzg/cXxhfO6nqxcmOcrotwCuvPLKP7z++utncPeS1MfDDz/8s6qaW8vXziL4g1XVceA4wPz8fC0uLm7m3UvSy16S/1zr187ir3SeAPZOHO8Zn5MkXUZmEfwF4F3jv9a5GXimqn7t6RxJ0taa+pROki8BtwC7klwAPgK8EqCqPgWcAG4DloBngfds1LCSpLWbGvyqOjLl+gL+emYTSZI2hO+0laQmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqYlBwU9yIMnjSZaS3HWR69+Q5IEkjyR5NMltsx9VkrQeU4OfZAdwDLgV2A8cSbJ/1bK/B+6vqhuAw8A/z3pQSdL6DHmEfxOwVFXnquo54D7g0Ko1BbxmfPm1wE9mN6IkaRaGBH83cH7i+ML43KSPArcnuQCcAN5/sRtKcjTJYpLF5eXlNYwrSVqrWb1oewT4XFXtAW4DvpDk1267qo5X1XxVzc/Nzc3oriVJQwwJ/hPA3onjPeNzk+4A7geoqu8CrwJ2zWJASdJsDAn+aWBfkmuTXMHoRdmFVWt+DLwNIMmbGAXf52wk6TIyNfhV9TxwJ3ASeIzRX+OcSXJPkoPjZR8E3pvke8CXgHdXVW3U0JKkl27nkEVVdYLRi7GT5+6euHwWeMtsR5MkzZLvtJWkJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNTEo+EkOJHk8yVKSuy6x5p1JziY5k+SLsx1TkrReO6ctSLIDOAb8GXABOJ1koarOTqzZB/wd8JaqejrJ6zZqYEnS2gx5hH8TsFRV56rqOeA+4NCqNe8FjlXV0wBV9eRsx5QkrdeQ4O8Gzk8cXxifm3QdcF2S7yQ5leTAxW4oydEki0kWl5eX1zaxJGlNZvWi7U5gH3ALcAT4TJKrVy+qquNVNV9V83NzczO6a0nSEEOC/wSwd+J4z/jcpAvAQlX9qqp+CPyA0Q8ASdJlYkjwTwP7klyb5ArgMLCwas3XGD26J8kuRk/xnJvdmJKk9Zoa/Kp6HrgTOAk8BtxfVWeS3JPk4HjZSeCpJGeBB4APVdVTGzW0JOmlS1VtyR3Pz8/X4uLilty3JL1cJXm4qubX8rW+01aSmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmBgU/yYEkjydZSnLXi6x7R5JKMj+7ESVJszA1+El2AMeAW4H9wJEk+y+y7irgb4CHZj2kJGn9hjzCvwlYqqpzVfUccB9w6CLrPgZ8HPjFDOeTJM3IkODvBs5PHF8Yn/s/SW4E9lbV11/shpIcTbKYZHF5efklDytJWrt1v2ib5BXAJ4APTltbVcerar6q5ufm5tZ715Kkl2BI8J8A9k4c7xmfe8FVwJuBbyf5EXAzsOALt5J0eRkS/NPAviTXJrkCOAwsvHBlVT1TVbuq6pqqugY4BRysqsUNmViStCZTg19VzwN3AieBx4D7q+pMknuSHNzoASVJs7FzyKKqOgGcWHXu7kusvWX9Y0mSZs132kpSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmhgU/CQHkjyeZCnJXRe5/gNJziZ5NMk3k7xx9qNKktZjavCT7ACOAbcC+4EjSfavWvYIMF9VfwB8FfiHWQ8qSVqfIY/wbwKWqupcVT0H3AccmlxQVQ9U1bPjw1PAntmOKUlaryHB3w2cnzi+MD53KXcA37jYFUmOJllMsri8vDx8SknSus30RdsktwPzwL0Xu76qjlfVfFXNz83NzfKuJUlT7Byw5glg78TxnvG5/yfJ24EPA2+tql/OZjxJ0qwMeYR/GtiX5NokVwCHgYXJBUluAD4NHKyqJ2c/piRpvaYGv6qeB+4ETgKPAfdX1Zkk9yQ5OF52L/Bq4CtJ/j3JwiVuTpK0RYY8pUNVnQBOrDp398Tlt894LknSjPlOW0lqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpoYFPwkB5I8nmQpyV0Xuf43knx5fP1DSa6Z+aSSpHWZGvwkO4BjwK3AfuBIkv2rlt0BPF1Vvwv8E/DxWQ8qSVqfIY/wbwKWqupcVT0H3AccWrXmEPBv48tfBd6WJLMbU5K0XjsHrNkNnJ84vgD80aXWVNXzSZ4Bfhv42eSiJEeBo+PDXyb5/lqG3oZ2sWqvGnMvVrgXK9yLFb+31i8cEvyZqarjwHGAJItVNb+Z93+5ci9WuBcr3IsV7sWKJItr/dohT+k8AeydON4zPnfRNUl2Aq8FnlrrUJKk2RsS/NPAviTXJrkCOAwsrFqzAPzl+PJfAN+qqprdmJKk9Zr6lM74Ofk7gZPADuCzVXUmyT3AYlUtAP8KfCHJEvBzRj8Upjm+jrm3G/dihXuxwr1Y4V6sWPNexAfiktSD77SVpCYMviQ1seHB92MZVgzYiw8kOZvk0STfTPLGrZhzM0zbi4l170hSSbbtn+QN2Ysk7xx/b5xJ8sXNnnGzDPg/8oYkDyR5ZPz/5LatmHOjJflskicv9V6ljHxyvE+PJrlx0A1X1Yb9Y/Qi738AvwNcAXwP2L9qzV8BnxpfPgx8eSNn2qp/A/fiT4HfHF9+X+e9GK+7CngQOAXMb/XcW/h9sQ94BPit8fHrtnruLdyL48D7xpf3Az/a6rk3aC/+BLgR+P4lrr8N+AYQ4GbgoSG3u9GP8P1YhhVT96KqHqiqZ8eHpxi952E7GvJ9AfAxRp/L9IvNHG6TDdmL9wLHquppgKp6cpNn3CxD9qKA14wvvxb4ySbOt2mq6kFGf/F4KYeAz9fIKeDqJK+fdrsbHfyLfSzD7kutqarngRc+lmG7GbIXk+5g9BN8O5q6F+NfUfdW1dc3c7AtMOT74jrguiTfSXIqyYFNm25zDdmLjwK3J7kAnADevzmjXXZeak+ATf5oBQ2T5HZgHnjrVs+yFZK8AvgE8O4tHuVysZPR0zq3MPqt78Ekv19V/7WVQ22RI8Dnquofk/wxo/f/vLmq/merB3s52OhH+H4sw4ohe0GStwMfBg5W1S83abbNNm0vrgLeDHw7yY8YPUe5sE1fuB3yfXEBWKiqX1XVD4EfMPoBsN0M2Ys7gPsBquq7wKsYfbBaN4N6stpGB9+PZVgxdS+S3AB8mlHst+vztDBlL6rqmaraVVXXVNU1jF7POFhVa/7QqMvYkP8jX2P06J4kuxg9xXNuE2fcLEP24sfA2wCSvIlR8Jc3dcrLwwLwrvFf69wMPFNVP532RRv6lE5t3McyvOwM3It7gVcDXxm/bv3jqjq4ZUNvkIF70cLAvTgJ/HmSs8B/Ax+qqm33W/DAvfgg8Jkkf8voBdx3b8cHiEm+xOiH/K7x6xUfAV4JUFWfYvT6xW3AEvAs8J5Bt7sN90qSdBG+01aSmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElq4n8BzPZculjwdYoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Plotting Results\"\"\"\n",
    "\n",
    "# print(\"Checking final accuracy on training data.\")\n",
    "# check_accuracy(train_loader, model)\n",
    "\n",
    "# print(\"Checking final accuracy on testing data.\")\n",
    "# check_accuracy(test_loader, model)\n",
    "\n",
    "\n",
    "\n",
    "def plot(loss, train_acc, test_acc):\n",
    "    epochs_range = range(0, len(train_acc))\n",
    "    \n",
    "    #Creating Scatter Plot for Loss\n",
    "    plt.figure()\n",
    "    plt.scatter(range(0, len(all_losses)), loss)\n",
    "    plt.plot(range(0, len(all_losses)), loss)\n",
    "    \n",
    "    #Creating Scatter Plot for Accuracy\n",
    "    plt.figure()\n",
    "    plt.scatter(epochs_range, train_acc)\n",
    "    plt.scatter(epochs_range, test_acc)\n",
    "    plt.plot(epochs_range, train_acc)\n",
    "    plt.plot(epochs_range, test_acc)\n",
    "    \n",
    "    \n",
    "    #Creating Linear Trendlines for Train Accuracy and Test Accuracy\n",
    "    epochs_trend = np.linspace(epochs_range[0], epochs_range[-1], 100)\n",
    "    \n",
    "    train_coeff = np.polyfit(epochs_range, train_acc, 1)\n",
    "    train_acc_trend = train_coeff[0]*epochs_trend + train_coeff[1]   #m*x + b\n",
    "    plt.plot(epochs_trend, train_acc_trend,'b-')\n",
    "    \n",
    "    test_coeff = np.polyfit(epochs_range, test_acc, 1)\n",
    "    test_acc_trend = test_coeff[0]*epochs_trend + test_coeff[1]   #m*x + b\n",
    "    plt.plot(epochs_trend, test_acc_trend,'r-')\n",
    "    print(\"test trendline slope: \" + str(test_coeff[0]))\n",
    "    \n",
    "    \n",
    "    #Saving plot to file\n",
    "    now = datetime.now()\n",
    "    # dd/mm/YY H:M:S\n",
    "    dt_string = now.strftime(\"%d,%m,%Y_%H,%M,%S\")\n",
    "#     plt.savefig('../plots/loss_accuracy_' + dt_string + '.png')\n",
    "\n",
    "plot(all_losses, all_train_acc, all_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Getting prediction on single custom image\"\"\"\n",
    "IMG_FILE = \"../test_face2.jpg\"\n",
    "\n",
    "test_img = torch.Tensor(cv2.cvtColor(cv2.imread(IMG_FILE), cv2.COLOR_BGR2GRAY))   #getting image with shape (48, 48)\n",
    "test_img = test_img.unsqueeze(0).unsqueeze(0)  #adding 2 dimensions to the image to get it to shape (1, 1, 48, 48). The 1st dimension represents batch of 1, the second represents color channels (I think)\n",
    "outputs = model(test_img)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Getting prediction on a random image from the dataset (and retreiving label)\"\"\"\n",
    "import random\n",
    "item_tuple = dataset.__getitem__(random.randint(0, dataset.__len__()-1))\n",
    "image = item_tuple[0]\n",
    "label = item_tuple[1]*100\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "image = torch.Tensor(image)\n",
    "image = image.unsqueeze(0).unsqueeze(0)  #adding 2 dimensions to the image to get it to shape (1, 1, 48, 48). The 1st dimension represents batch of 1, the second represents color channels (I think)\n",
    "outputs = model(image) * 100\n",
    "print(\"prediction: %f.      Label: %f\" % (outputs, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7ed9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Getting prediction on a random image from the dataset (and retreiving label)\"\"\"\n",
    "# import random\n",
    "# item_tuple = dataset.__getitem__(random.randint(0, dataset.__len__()-1))\n",
    "# image = item_tuple[0]\n",
    "# label = item_tuple[1]\n",
    "\n",
    "# %matplotlib inline\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.imshow(image)\n",
    "# plt.show()\n",
    "\n",
    "# __, img = torch.utils.data.random_split(dataset, [num_data_items-1, 1])\n",
    "# loader = DataLoader(dataset=img, batch_size=1, shuffle=True)\n",
    "# for batch_idx, (data, targets) in enumerate(loader):   #Looping through batches\n",
    "#     #Get data to cuda if possible\n",
    "#     data = data.to(device=device)             #data is a torch tensor of [batch size] 48x48 images (shape=[batch size,48,48])\n",
    "#     data = data.unsqueeze(1)                  #Add a dimension to the tensor for number of channels (which is 1)\n",
    "\n",
    "#     #Forward prop\n",
    "#     scores = model(data.float()).reshape(-1)\n",
    "\n",
    "#     print(\"prediction: %f.      Label: %d\" % (scores.item(), int(label.item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df24d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
