{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd3a1825",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imports\n",
    "\"\"\"\n",
    "# !pip install numpy\n",
    "# !pip install torch\n",
    "# !pip install torchvision\n",
    "# !pip install pandas\n",
    "# !pip install opencv-python\n",
    "# !pip install matplotlib\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import csv\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset_age import FacesDataset\n",
    "from data_augmentation import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e46022d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creating the Neural Network Class\"\"\"\n",
    "dropout = True;\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Input: 48 x 48 x 1 = 2304\n",
    "        ### Inputs to Conv2d: Incoming layers, outgoing layers, Frame size\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 2, 3)  #48 --> 46\n",
    "        self.batchnorm1 = nn.BatchNorm2d(2)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  #46 --> 23\n",
    "        self.conv2 = nn.Conv2d(2, 4, 3, stride=2)  #23 --> 11\n",
    "        self.batchnorm2 = nn.BatchNorm2d(4)\n",
    "        self.conv3 = nn.Conv2d(4, 8, 3, stride=2) #11 --> 5\n",
    "        self.batchnorm3 = nn.BatchNorm2d(8)\n",
    "\n",
    "        # Activation function to use\n",
    "        self.activation = F.relu\n",
    "    \n",
    "        self.fc1 = nn.Linear(200, 50)\n",
    "        self.batchnorm_fc1 = nn.BatchNorm1d(50)\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.5)    #p = probability of a neuron being dropped\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        self.batchnorm_fc2 = nn.BatchNorm1d(10)\n",
    "        self.dropout2 = torch.nn.Dropout(p=0.5)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.batchnorm1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.activation(self.batchnorm2(self.conv2(x)))\n",
    "        x = self.activation(self.batchnorm3(self.conv3(x)))\n",
    "        x = x.view(-1, 200)\n",
    "        x = self.activation(self.batchnorm_fc1(self.fc1(x)))\n",
    "        if dropout:\n",
    "            x = self.dropout1(x)\n",
    "        x = self.activation(self.batchnorm_fc2(self.fc2(x)))\n",
    "        if dropout:\n",
    "            x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ffbf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Setting up neural network parameters, defining accuracy function\"\"\"\n",
    "model = Net()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "# model.to(device)\n",
    "\n",
    "target_epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "# learning_rate = 0.000000001  #11/12 2:07 PM (works, small range of 14-31)\n",
    "# learning_rate = 0.0000000005   #11/12 2:15 PM (works, range of -7 to 50. seems to be making real (but inaccurate predictions))\n",
    "learning_rate = 0.001\n",
    "gamma = 0.95\n",
    "\n",
    "# criterion = nn.L1Loss()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "\n",
    "data_path = \"../age_gender.csv\"\n",
    "\n",
    "dataset = FacesDataset(csv_file=data_path)\n",
    "num_data_items = dataset.__len__()\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [int(round(num_data_items*0.51)), int(round(num_data_items*0.49))])\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "save_model = \"model.pth\"\n",
    "\n",
    "if not os.path.exists(save_model):   #If there is not already a saved model file\n",
    "    start_epoch = 0\n",
    "    \n",
    "    all_losses = []\n",
    "    all_train_acc = []\n",
    "    all_test_acc = []\n",
    "else:\n",
    "    checkpoint = torch.load(save_model, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    all_losses = checkpoint['all_losses']\n",
    "    all_train_acc = checkpoint['all_train_acc']\n",
    "    all_test_acc = checkpoint['all_test_acc']\n",
    "\n",
    "\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    \"\"\"\n",
    "    Checks accuracy of the model by running it on the data in the dataloader passed as a parameter\n",
    "    \n",
    "    The closer the returned score is to 0, the better\n",
    "    \"\"\"\n",
    "    num_correct_age = 0\n",
    "    num_samples = loader.__len__()\n",
    "    \n",
    "    model.eval()  #Setting to eval mode will cause the model to ignore the dropout layers\n",
    "    \n",
    "    with torch.no_grad():  #speeds up process\n",
    "        age_diffs_total = 0\n",
    "        num_batches = 0\n",
    "        for batch_idx, (x, y) in enumerate(loader):   #Looping through batches\n",
    "            x = x.to(device=device)   #shape: (batch size, 48, 48)\n",
    "            y = y.to(device=device)   #shape: (batch size, 3)\n",
    "            \n",
    "            #GETTING AND FORMATTING MODEL PREDICTIONS\n",
    "            x = x.unsqueeze(1)   #Add a dimension to the tensor for number of channels (which is 1)\n",
    "#             scores = model(x.float())   #Shape: (batch size, 3)\n",
    "            scores = model(x.float()).reshape(-1)   #Shape: (batch size, 3)\n",
    "#             print(\"scores: \" + str(scores))\n",
    "            \n",
    "            #CALCULATING ACCURACY SCORE\n",
    "            age_diffs = torch.abs(scores - y)\n",
    "            age_diff_avg = torch.mean(age_diffs)\n",
    "            \n",
    "            age_diffs_total += age_diff_avg\n",
    "            num_batches += 1\n",
    "        \n",
    "#         print(f'accuracy score (the closer to zero, the better): {total_accuracy}')\n",
    "    return age_diffs_total/num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba574bcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.023131572037797282, Train Acc: 10.229072570800781, Test Acc: 10.474201202392578\n",
      "Epoch: 7, Loss: 0.02204768105025684, Train Acc: 9.511990547180176, Test Acc: 9.815975189208984\n",
      "Epoch: 8, Loss: 0.021012525483177454, Train Acc: 10.159575462341309, Test Acc: 10.422041893005371\n",
      "Epoch: 9, Loss: 0.020487598994766515, Train Acc: 9.983158111572266, Test Acc: 10.256836891174316\n",
      "Epoch: 10, Loss: 0.020105106719749827, Train Acc: 10.671960830688477, Test Acc: 10.841047286987305\n",
      "Epoch: 11, Loss: 0.019597159728787287, Train Acc: 9.113856315612793, Test Acc: 9.53615951538086\n",
      "Epoch: 12, Loss: 0.01973833987876162, Train Acc: 8.887048721313477, Test Acc: 9.350186347961426\n",
      "Epoch: 13, Loss: 0.019416247577672557, Train Acc: 9.142993927001953, Test Acc: 9.6106538772583\n",
      "Epoch: 14, Loss: 0.019098293036222458, Train Acc: 9.115715980529785, Test Acc: 9.521824836730957\n",
      "Epoch: 15, Loss: 0.019068622907436397, Train Acc: 8.918054580688477, Test Acc: 9.362152099609375\n",
      "Epoch: 16, Loss: 0.01895853209188553, Train Acc: 8.644694328308105, Test Acc: 9.172541618347168\n",
      "Epoch: 17, Loss: 0.019081395217981287, Train Acc: 9.231645584106445, Test Acc: 9.557937622070312\n",
      "Epoch: 18, Loss: 0.018606177775100582, Train Acc: 9.593466758728027, Test Acc: 10.048176765441895\n",
      "Epoch: 19, Loss: 0.01819178853344133, Train Acc: 8.594864845275879, Test Acc: 9.106661796569824\n",
      "Epoch: 20, Loss: 0.0185598910967302, Train Acc: 8.612712860107422, Test Acc: 9.074453353881836\n",
      "Epoch: 21, Loss: 0.018391422843609853, Train Acc: 8.179206848144531, Test Acc: 8.733604431152344\n",
      "Epoch: 22, Loss: 0.01811354878117089, Train Acc: 9.228710174560547, Test Acc: 9.76821517944336\n",
      "Epoch: 23, Loss: 0.01796527554603816, Train Acc: 8.355870246887207, Test Acc: 8.946273803710938\n",
      "Epoch: 24, Loss: 0.018343775542379016, Train Acc: 8.683938026428223, Test Acc: 9.200621604919434\n",
      "Epoch: 25, Loss: 0.017881802342359036, Train Acc: 8.31798267364502, Test Acc: 8.905010223388672\n",
      "Epoch: 26, Loss: 0.01794183368624617, Train Acc: 8.329371452331543, Test Acc: 8.889442443847656\n",
      "Epoch: 27, Loss: 0.017649940348097255, Train Acc: 8.30700969696045, Test Acc: 8.881608009338379\n",
      "Epoch: 28, Loss: 0.018104288019929773, Train Acc: 8.773887634277344, Test Acc: 9.330939292907715\n",
      "Epoch: 29, Loss: 0.017588637100296126, Train Acc: 9.169218063354492, Test Acc: 9.595708847045898\n",
      "Epoch: 30, Loss: 0.01761171426845803, Train Acc: 8.131985664367676, Test Acc: 8.735206604003906\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Training\"\"\"\n",
    "def train_batch(data, targets):\n",
    "    #Get data to cuda if possible\n",
    "        data = data.to(device=device)             #data is a torch tensor of [batch size] 48x48 images (shape=[batch size,48,48])\n",
    "        data = data.unsqueeze(1)                  #Add a dimension to the tensor for number of channels (which is 1)\n",
    "#         print(\"data.shape: \" + str(data.shape))\n",
    "        targets = targets.to(device=device)       #data is a torch tensor of (shape=[batch size,1])\n",
    "#         print(\"targets.shape: \" + str(targets.shape))\n",
    "#         print(\"data[0,:,:].shape: \" + str(np.array(data[0,:,:].shape)))\n",
    "#         cv2.imwrite(\"test.png\", np.array(data[0,:,:]))\n",
    "        \n",
    "        #Forward prop\n",
    "        scores = model(data.float()).reshape(-1)\n",
    "        \n",
    "        #Calculating Accuracy Score\n",
    "        #Old method (not using check_accuracy())\n",
    "#         age_diffs = torch.abs(scores - targets)\n",
    "#         train_acc = torch.mean(age_diffs).item() * 100        \n",
    "\n",
    "        loss = criterion(scores, targets)\n",
    "        \n",
    "        #Backward prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()  #gradient descent\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        \n",
    "\n",
    "for epoch in range(start_epoch+1, target_epochs+1):  #Looping through epochs\n",
    "    losses = []\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):   #Looping through batches\n",
    "        train_batch(data, targets)   #Original Data\n",
    "        data, targets = horiz_flip((data, targets), batch_size)\n",
    "        train_batch(data, targets)   #Augmented Data: Horizontal Flip\n",
    "         \n",
    "    scheduler.step()\n",
    "    \n",
    "    #Calculating Accuray Score using check_accuracy()\n",
    "    train_acc = check_accuracy(train_loader, model) * 100\n",
    "    all_train_acc.append(train_acc.to(\"cpu\").numpy())\n",
    "    test_acc = check_accuracy(test_loader, model) * 100\n",
    "    all_test_acc.append(test_acc.to(\"cpu\").numpy())\n",
    "    \n",
    "    #Calculating Loss\n",
    "    l = sum(losses)/len(losses)\n",
    "    all_losses.append(l)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, Loss: {l}, Train Acc: {train_acc}, Test Acc: {test_acc}\")\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'all_losses': all_losses,\n",
    "        'all_train_acc': all_train_acc,\n",
    "        'all_test_acc': all_test_acc\n",
    "    }, save_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Plotting Results\"\"\"\n",
    "\n",
    "def plot(loss, train_acc, test_acc):\n",
    "    epochs_range = range(0, len(train_acc))\n",
    "    \n",
    "    #Creating Scatter Plot for Loss\n",
    "    plt.figure()\n",
    "    plt.scatter(range(0, len(all_losses)), loss)\n",
    "    plt.plot(range(0, len(all_losses)), loss)\n",
    "    \n",
    "    #Creating Scatter Plot for Accuracy\n",
    "    plt.figure()\n",
    "    plt.scatter(epochs_range, train_acc)\n",
    "    plt.scatter(epochs_range, test_acc)\n",
    "    plt.plot(epochs_range, train_acc)\n",
    "    plt.plot(epochs_range, test_acc)\n",
    "    \n",
    "    \n",
    "    #Creating Linear Trendlines for Train Accuracy and Test Accuracy\n",
    "    epochs_trend = np.linspace(epochs_range[0], epochs_range[-1], 100)\n",
    "    \n",
    "    train_coeff = np.polyfit(epochs_range, train_acc, 1)\n",
    "    train_acc_trend = train_coeff[0]*epochs_trend + train_coeff[1]   #m*x + b\n",
    "    plt.plot(epochs_trend, train_acc_trend,'b-')\n",
    "    \n",
    "    test_coeff = np.polyfit(epochs_range, test_acc, 1)\n",
    "    test_acc_trend = test_coeff[0]*epochs_trend + test_coeff[1]   #m*x + b\n",
    "    plt.plot(epochs_trend, test_acc_trend,'r-')\n",
    "    print(\"test trendline slope: \" + str(test_coeff[0]))\n",
    "    \n",
    "    \n",
    "    #Saving plot to file\n",
    "    now = datetime.now()\n",
    "    # dd/mm/YY H:M:S\n",
    "    dt_string = now.strftime(\"%d,%m,%Y_%H,%M,%S\")\n",
    "#     plt.savefig('../plots/loss_accuracy_' + dt_string + '.png')\n",
    "\n",
    "plot(all_losses, all_train_acc, all_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Getting prediction on single custom image\"\"\"\n",
    "IMG_FILE = \"../test_face2.jpg\"\n",
    "\n",
    "model.eval()\n",
    "test_img = torch.Tensor(cv2.cvtColor(cv2.imread(IMG_FILE), cv2.COLOR_BGR2GRAY))   #getting image with shape (48, 48)\n",
    "test_img = test_img.unsqueeze(0).unsqueeze(0)  #adding 2 dimensions to the image to get it to shape (1, 1, 48, 48). The 1st dimension represents batch of 1, the second represents color channels (I think)\n",
    "outputs = model(test_img.to(device=device))\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Getting prediction on a random image from the dataset (and retreiving label)\"\"\"\n",
    "import random\n",
    "item_tuple = dataset.__getitem__(random.randint(0, dataset.__len__()-1))\n",
    "image = item_tuple[0]\n",
    "label = item_tuple[1]*100\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "image = torch.Tensor(image)\n",
    "image = image.unsqueeze(0).unsqueeze(0)  #adding 2 dimensions to the image to get it to shape (1, 1, 48, 48). The 1st dimension represents batch of 1, the second represents color channels (I think)\n",
    "outputs = model(image.to(device=device)) * 100\n",
    "print(\"prediction: %f.      Label: %f\" % (outputs, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7ed9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Getting prediction on a random image from the dataset (and retreiving label)\"\"\"\n",
    "# import random\n",
    "# item_tuple = dataset.__getitem__(random.randint(0, dataset.__len__()-1))\n",
    "# image = item_tuple[0]\n",
    "# label = item_tuple[1]\n",
    "\n",
    "# %matplotlib inline\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.imshow(image)\n",
    "# plt.show()\n",
    "\n",
    "# __, img = torch.utils.data.random_split(dataset, [num_data_items-1, 1])\n",
    "# loader = DataLoader(dataset=img, batch_size=1, shuffle=True)\n",
    "# for batch_idx, (data, targets) in enumerate(loader):   #Looping through batches\n",
    "#     #Get data to cuda if possible\n",
    "#     data = data.to(device=device)             #data is a torch tensor of [batch size] 48x48 images (shape=[batch size,48,48])\n",
    "#     data = data.unsqueeze(1)                  #Add a dimension to the tensor for number of channels (which is 1)\n",
    "\n",
    "#     #Forward prop\n",
    "#     scores = model(data.float()).reshape(-1)\n",
    "\n",
    "#     print(\"prediction: %f.      Label: %d\" % (scores.item(), int(label.item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df24d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
